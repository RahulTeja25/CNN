{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "c5yGyGmXf39_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "nM84bAhMgDQz",
    "outputId": "21acaafe-54c4-4d65-b570-72c1fc61bc4f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>d</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>b</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>c</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>766 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     f1   f2  f3  f4   f5    f6     f7  target\n",
       "0     6  148  72  35    0  33.6  0.627       1\n",
       "1     1   85  66  29    0  26.6  0.351       0\n",
       "2     8  183  64   0    0  23.3  0.672       1\n",
       "3     1   89  66  23   94  28.1  0.167       0\n",
       "4     0  137  40  35  168  43.1  2.288       1\n",
       "..   ..  ...  ..  ..  ...   ...    ...     ...\n",
       "761   9   89  62   0    0  22.5      e       0\n",
       "762  10  101  76  48  180     d  0.171       0\n",
       "763   2  122  70  27    b  36.8   0.34       0\n",
       "764   c  121  72  23  112  26.2  0.245       0\n",
       "765   1  126  60   a    0  30.1  0.349       1\n",
       "\n",
       "[766 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=\"dataset.csv\"\n",
    "df=pd.read_csv(file)\n",
    "df.dropna(inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "EYcWJp58TYq-"
   },
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "  df[i] = pd.to_numeric(df[i], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "mh0xoJefTdmv"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "D0ENBt0uUSbN"
   },
   "outputs": [],
   "source": [
    "df['f3']=df['f3'].astype('float')\n",
    "# for i in range(0,7):\n",
    "#   df[i]=df[i].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "fKe21RbNiSgi"
   },
   "outputs": [],
   "source": [
    "df['target']=df['target'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyBtBfrJU0Uz",
    "outputId": "ceb3690f-c749-4562-8dbc-42d164d673a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1        float64\n",
       "f2        float64\n",
       "f3        float64\n",
       "f4        float64\n",
       "f5        float64\n",
       "f6        float64\n",
       "f7        float64\n",
       "target    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "E_8yZhgtgH_G",
    "outputId": "1e9ef532-56cd-454c-a0d9-33e0fe1da133"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>760.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.834211</td>\n",
       "      <td>120.969737</td>\n",
       "      <td>69.119737</td>\n",
       "      <td>20.507895</td>\n",
       "      <td>80.234211</td>\n",
       "      <td>31.998684</td>\n",
       "      <td>0.473250</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.364762</td>\n",
       "      <td>32.023301</td>\n",
       "      <td>19.446088</td>\n",
       "      <td>15.958029</td>\n",
       "      <td>115.581444</td>\n",
       "      <td>7.899724</td>\n",
       "      <td>0.332277</td>\n",
       "      <td>0.477284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.375500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>128.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               f1          f2          f3          f4          f5          f6  \\\n",
       "count  760.000000  760.000000  760.000000  760.000000  760.000000  760.000000   \n",
       "mean     3.834211  120.969737   69.119737   20.507895   80.234211   31.998684   \n",
       "std      3.364762   32.023301   19.446088   15.958029  115.581444    7.899724   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   63.500000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   36.000000   32.000000   \n",
       "75%      6.000000  141.000000   80.000000   32.000000  128.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "               f7      target  \n",
       "count  760.000000  760.000000  \n",
       "mean     0.473250    0.350000  \n",
       "std      0.332277    0.477284  \n",
       "min      0.078000    0.000000  \n",
       "25%      0.243750    0.000000  \n",
       "50%      0.375500    0.000000  \n",
       "75%      0.627500    1.000000  \n",
       "max      2.420000    1.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45jXlxbhgUsF",
    "outputId": "cb5f1ec9-f443-4030-8684-5092d90afbe7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCCEdp5lgawn",
    "outputId": "bf12fe61-e1a8-4bea-ed29-20f404535957"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1        float64\n",
       "f2        float64\n",
       "f3        float64\n",
       "f4        float64\n",
       "f5        float64\n",
       "f6        float64\n",
       "f7        float64\n",
       "target    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZoPxoEMgbwL",
    "outputId": "223fd2cd-3f11-43f8-e979-8c8e21ebe221"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'target'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-VZluPRghJB",
    "outputId": "2f4d9a24-5c29-404d-d89d-e45d48f85598"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "Name: f1, dtype: float64\n",
      "0     99.0\n",
      "1    100.0\n",
      "Name: f2, dtype: float64\n",
      "0    70.0\n",
      "Name: f3, dtype: float64\n",
      "0    0.0\n",
      "Name: f4, dtype: float64\n",
      "0    0.0\n",
      "Name: f5, dtype: float64\n",
      "0    32.0\n",
      "Name: f6, dtype: float64\n",
      "0    0.254\n",
      "1    0.258\n",
      "Name: f7, dtype: float64\n",
      "0    0.0\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"f1\"].mode())\n",
    "print(df[\"f2\"].mode())\n",
    "print(df[\"f3\"].mode())\n",
    "print(df[\"f4\"].mode())\n",
    "print(df[\"f5\"].mode())\n",
    "print(df[\"f6\"].mode())\n",
    "print(df[\"f7\"].mode())\n",
    "print(df[\"target\"].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "xK336cx5V9oJ",
    "outputId": "7f95883e-cbe7-4a77-b3ce-22710d12e015"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129712</td>\n",
       "      <td>0.140772</td>\n",
       "      <td>-0.085733</td>\n",
       "      <td>-0.076051</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>-0.029486</td>\n",
       "      <td>0.224872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>0.129712</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151915</td>\n",
       "      <td>0.057686</td>\n",
       "      <td>0.333169</td>\n",
       "      <td>0.217232</td>\n",
       "      <td>0.137290</td>\n",
       "      <td>0.464028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>0.140772</td>\n",
       "      <td>0.151915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206237</td>\n",
       "      <td>0.087869</td>\n",
       "      <td>0.281387</td>\n",
       "      <td>0.042023</td>\n",
       "      <td>0.065462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4</th>\n",
       "      <td>-0.085733</td>\n",
       "      <td>0.057686</td>\n",
       "      <td>0.206237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437391</td>\n",
       "      <td>0.391973</td>\n",
       "      <td>0.185557</td>\n",
       "      <td>0.078517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5</th>\n",
       "      <td>-0.076051</td>\n",
       "      <td>0.333169</td>\n",
       "      <td>0.087869</td>\n",
       "      <td>0.437391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199214</td>\n",
       "      <td>0.185638</td>\n",
       "      <td>0.132497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f6</th>\n",
       "      <td>0.016894</td>\n",
       "      <td>0.217232</td>\n",
       "      <td>0.281387</td>\n",
       "      <td>0.391973</td>\n",
       "      <td>0.199214</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140369</td>\n",
       "      <td>0.290889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7</th>\n",
       "      <td>-0.029486</td>\n",
       "      <td>0.137290</td>\n",
       "      <td>0.042023</td>\n",
       "      <td>0.185557</td>\n",
       "      <td>0.185638</td>\n",
       "      <td>0.140369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.173610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.224872</td>\n",
       "      <td>0.464028</td>\n",
       "      <td>0.065462</td>\n",
       "      <td>0.078517</td>\n",
       "      <td>0.132497</td>\n",
       "      <td>0.290889</td>\n",
       "      <td>0.173610</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1        f2        f3        f4        f5        f6        f7  \\\n",
       "f1      1.000000  0.129712  0.140772 -0.085733 -0.076051  0.016894 -0.029486   \n",
       "f2      0.129712  1.000000  0.151915  0.057686  0.333169  0.217232  0.137290   \n",
       "f3      0.140772  0.151915  1.000000  0.206237  0.087869  0.281387  0.042023   \n",
       "f4     -0.085733  0.057686  0.206237  1.000000  0.437391  0.391973  0.185557   \n",
       "f5     -0.076051  0.333169  0.087869  0.437391  1.000000  0.199214  0.185638   \n",
       "f6      0.016894  0.217232  0.281387  0.391973  0.199214  1.000000  0.140369   \n",
       "f7     -0.029486  0.137290  0.042023  0.185557  0.185638  0.140369  1.000000   \n",
       "target  0.224872  0.464028  0.065462  0.078517  0.132497  0.290889  0.173610   \n",
       "\n",
       "          target  \n",
       "f1      0.224872  \n",
       "f2      0.464028  \n",
       "f3      0.065462  \n",
       "f4      0.078517  \n",
       "f5      0.132497  \n",
       "f6      0.290889  \n",
       "f7      0.173610  \n",
       "target  1.000000  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "O-0Wxg8RKkCN"
   },
   "outputs": [],
   "source": [
    "X=df.drop(['target','f1','f3','f4','f5','f7'],axis=1).values\n",
    "y=df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "DCRxCYPbQ6yy"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "DqZf_Vzfh7bn"
   },
   "outputs": [],
   "source": [
    "# X = torch.FloatTensor(X)\n",
    "# y = torch.FloatTensor(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "id": "qWI8EbnZj_LM"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,shuffle=True,stratify=y,random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "id": "zSk6ku6Bkb5Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "id": "py_xX6XWingJ"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(16, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x=self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OUYXhFghk1Zu",
    "outputId": "82b26500-5b7f-4f89-9501-51c5c3f0c928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear1): Linear(in_features=2, out_features=16, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (linear3): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "id": "DMDGXGi7YM1I"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "ac_tr,ac_ts,ls_tr,ls_ts=[],[],[],[]\n",
    " \n",
    "def model_train(model, X_train, y_train, X_test, y_test):\n",
    "    loss_function= nn.BCELoss() \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    n_epochs = 100\n",
    "    batch_size = 50\n",
    "    least_loss=1\n",
    "    for epoch in range(n_epochs):\n",
    "        for start in range(0, len(X_train), batch_size):\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                X_batch = torch.FloatTensor(X_batch)\n",
    "                y_batch = torch.FloatTensor(y_batch).reshape(-1, 1)\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_function(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "        model.eval()\n",
    "        ytrain_pred,ytest_pred=model(X_train),model(X_test)\n",
    "        trloss,tsloss=loss_function(ytrain_pred, y_train),loss_function(ytest_pred, y_test)\n",
    "        ytrain_loss,ytest_loss=trloss.item(),tsloss.item()\n",
    "        tracc,tsacc=(ytrain_pred.round() == y_train).float().mean(),(ytest_pred.round() == y_test).float().mean()\n",
    "        \n",
    "        ac_tr.append(tracc)\n",
    "        ac_ts.append(tsacc)\n",
    "        ls_tr.append(ytrain_loss)\n",
    "        ls_ts.append(ytest_loss)\n",
    "        \n",
    "        if tsloss<least_loss:\n",
    "            least_loss=tsloss\n",
    "            torch.save(model.state_dict(),'least_loss_model1.pth')\n",
    "    return tsacc,tracc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.FloatTensor(y_train).reshape(-1, 1)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(y_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "id": "PkraRTVZlCeF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 76.32%\n"
     ]
    }
   ],
   "source": [
    "test_acc,train_acc=model_train(model, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-kjiNP0ozQY",
    "outputId": "013ba76a-a02b-4cc1-bc86-8ba82ae5db30"
   },
   "outputs": [],
   "source": [
    "# model=NeuralNetwork()\n",
    "# model.load_state_dict(torch.load('least_loss_model1.pth'))\n",
    "# model.eval()\n",
    "# prediction = model(X_test)\n",
    "# acc = (torch.round(prediction) == y_test).float().mean()\n",
    "# print('Accuracy for test data: {:.2f}%'.format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "id": "hrl4yf0_jaEW",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ls_tr,label='train_loss')\n",
    "plt.plot(ls_ts,label='test_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part-2\n",
    "# tuning hyperparamters\n",
    "\n",
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class dropoutNeuralNetwork(nn.Module):\n",
    "    def __init__(self,prob):\n",
    "        super(dropoutNeuralNetwork,self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(prob[0])\n",
    "        self.linear2 = nn.Linear(16, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(prob[1])\n",
    "        self.linear3 = nn.Linear(8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear3(x)\n",
    "        x=self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of dropoutNeuralNetwork(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (linear1): Linear(in_features=2, out_features=16, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (linear3): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "## Dropout model with p=[0.05,0.1]\n",
    "\n",
    "drop_model_1=dropoutNeuralNetwork([0.1,0.2])\n",
    "print(drop_model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 77.89%\n"
     ]
    }
   ],
   "source": [
    "drop_test_acc,drop_train_acc=model_train(drop_model_1, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(drop_test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of dropoutNeuralNetwork(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (linear1): Linear(in_features=2, out_features=16, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (linear3): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "## Dropout model with p=[0.4,0.3]\n",
    "\n",
    "drop_model_2=dropoutNeuralNetwork([0.4,0.3])\n",
    "print(drop_model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 76.32%\n"
     ]
    }
   ],
   "source": [
    "drop_test_acc,drop_train_acc=model_train(drop_model_2, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(drop_test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of dropoutNeuralNetwork(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (linear1): Linear(in_features=2, out_features=16, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (linear3): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "## Dropout model with p=[0.3,0.2]\n",
    "\n",
    "drop_model_3=dropoutNeuralNetwork([0.3,0.2])\n",
    "print(drop_model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 78.42%\n"
     ]
    }
   ],
   "source": [
    "drop_test_acc,drop_train_acc=model_train(drop_model_3, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(drop_test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Base model is using dropout with p[0.3,0.2] with highest accuracy \n",
    "drop_model_1=dropoutNeuralNetwork([0.3,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing optimizer to SGD on the base model\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "ac_tr,ac_ts,ls_tr,ls_ts=[],[],[],[]\n",
    " \n",
    "def model_train(model, X_train, y_train, X_test, y_test):\n",
    "    loss_function= nn.BCELoss() \n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001,momentum=0.9)\n",
    "    n_epochs = 100\n",
    "    batch_size = 50\n",
    "    least_loss=1\n",
    "    for epoch in range(n_epochs):\n",
    "        for start in range(0, len(X_train), batch_size):\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                X_batch = torch.FloatTensor(X_batch)\n",
    "                y_batch = torch.FloatTensor(y_batch).reshape(-1, 1)\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_function(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "        model.eval()\n",
    "        ytrain_pred,ytest_pred=model(X_train),model(X_test)\n",
    "        trloss,tsloss=loss_function(ytrain_pred, y_train),loss_function(ytest_pred, y_test)\n",
    "        ytrain_loss,ytest_loss=trloss.item(),tsloss.item()\n",
    "        tracc,tsacc=(ytrain_pred.round() == y_train).float().mean(),(ytest_pred.round() == y_test).float().mean()\n",
    "        \n",
    "        ac_tr.append(tracc)\n",
    "        ac_ts.append(tsacc)\n",
    "        ls_tr.append(ytrain_loss)\n",
    "        ls_ts.append(ytest_loss)\n",
    "        \n",
    "        if tsloss<least_loss:\n",
    "            least_loss=tsloss\n",
    "            torch.save(model.state_dict(),'least_loss_model1.pth')\n",
    "    return tsacc,tracc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 77.89%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for SGD optimizer\n",
    "\n",
    "test_acc,train_acc=model_train(drop_model_3, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing optimizer to RMSprop on the base model\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "ac_tr,ac_ts,ls_tr,ls_ts=[],[],[],[]\n",
    " \n",
    "def model_train(model, X_train, y_train, X_test, y_test):\n",
    "    loss_function= nn.BCELoss() \n",
    "    optimizer = optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0.9, centered=False)\n",
    "    n_epochs = 100\n",
    "    batch_size = 50\n",
    "    least_loss=1\n",
    "    for epoch in range(n_epochs):\n",
    "        for start in range(0, len(X_train), batch_size):\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                X_batch = torch.FloatTensor(X_batch)\n",
    "                y_batch = torch.FloatTensor(y_batch).reshape(-1, 1)\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_function(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "        model.eval()\n",
    "        ytrain_pred,ytest_pred=model(X_train),model(X_test)\n",
    "        trloss,tsloss=loss_function(ytrain_pred, y_train),loss_function(ytest_pred, y_test)\n",
    "        ytrain_loss,ytest_loss=trloss.item(),tsloss.item()\n",
    "        tracc,tsacc=(ytrain_pred.round() == y_train).float().mean(),(ytest_pred.round() == y_test).float().mean()\n",
    "        \n",
    "        ac_tr.append(tracc)\n",
    "        ac_ts.append(tsacc)\n",
    "        ls_tr.append(ytrain_loss)\n",
    "        ls_ts.append(ytest_loss)\n",
    "        \n",
    "        if tsloss<least_loss:\n",
    "            least_loss=tsloss\n",
    "            torch.save(model.state_dict(),'least_loss_model1.pth')\n",
    "    return tsacc,tracc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 75.79%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for RMSprop optimizer\n",
    "\n",
    "test_acc,train_acc=model_train(drop_model_3, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing optimizer to Adagrad on the base model\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "ac_tr,ac_ts,ls_tr,ls_ts=[],[],[],[]\n",
    " \n",
    "def model_train(model, X_train, y_train, X_test, y_test):\n",
    "    loss_function= nn.BCELoss() \n",
    "    optimizer = optimizer = optim.Adagrad(model.parameters(), lr=0.001, lr_decay=0, weight_decay=0)\n",
    "    n_epochs = 100\n",
    "    batch_size = 50\n",
    "    least_loss=1\n",
    "    for epoch in range(n_epochs):\n",
    "        for start in range(0, len(X_train), batch_size):\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                X_batch = torch.FloatTensor(X_batch)\n",
    "                y_batch = torch.FloatTensor(y_batch).reshape(-1, 1)\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_function(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "        model.eval()\n",
    "        ytrain_pred,ytest_pred=model(X_train),model(X_test)\n",
    "        trloss,tsloss=loss_function(ytrain_pred, y_train),loss_function(ytest_pred, y_test)\n",
    "        ytrain_loss,ytest_loss=trloss.item(),tsloss.item()\n",
    "        tracc,tsacc=(ytrain_pred.round() == y_train).float().mean(),(ytest_pred.round() == y_test).float().mean()\n",
    "        \n",
    "        ac_tr.append(tracc)\n",
    "        ac_ts.append(tsacc)\n",
    "        ls_tr.append(ytrain_loss)\n",
    "        ls_ts.append(ytest_loss)\n",
    "        \n",
    "        if tsloss<least_loss:\n",
    "            least_loss=tsloss\n",
    "            torch.save(model.state_dict(),'least_loss_model1.pth')\n",
    "    return tsacc,tracc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 76.32%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for Adagrad optimizer\n",
    "\n",
    "test_acc,train_acc=model_train(drop_model_3, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tanh Activation function with dropout  \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ActivatedNeuralNetwork(nn.Module):\n",
    "    def __init__(self,prob):\n",
    "        super(ActivatedNeuralNetwork,self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 16)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(prob[0])\n",
    "        self.linear2 = nn.Linear(16, 8)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(prob[1])\n",
    "        self.linear3 = nn.Linear(8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear3(x)\n",
    "        x=self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_model_1=ActivatedNeuralNetwork([0.3,0.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "ac_tr,ac_ts,ls_tr,ls_ts=[],[],[],[]\n",
    " \n",
    "def model_train(model, X_train, y_train, X_test, y_test):\n",
    "    loss_function= nn.BCELoss() \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    n_epochs = 100\n",
    "    batch_size = 50\n",
    "    least_loss=1\n",
    "    for epoch in range(n_epochs):\n",
    "        for start in range(0, len(X_train), batch_size):\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                X_batch = torch.FloatTensor(X_batch)\n",
    "                y_batch = torch.FloatTensor(y_batch).reshape(-1, 1)\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_function(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "        model.eval()\n",
    "        ytrain_pred,ytest_pred=model(X_train),model(X_test)\n",
    "        trloss,tsloss=loss_function(ytrain_pred, y_train),loss_function(ytest_pred, y_test)\n",
    "        ytrain_loss,ytest_loss=trloss.item(),tsloss.item()\n",
    "        tracc,tsacc=(ytrain_pred.round() == y_train).float().mean(),(ytest_pred.round() == y_test).float().mean()\n",
    "        \n",
    "        ac_tr.append(tracc)\n",
    "        ac_ts.append(tsacc)\n",
    "        ls_tr.append(ytrain_loss)\n",
    "        ls_ts.append(ytest_loss)\n",
    "        \n",
    "        if tsloss<least_loss:\n",
    "            least_loss=tsloss\n",
    "            torch.save(model.state_dict(),'least_loss_model1.pth')\n",
    "    return tsacc,tracc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 77.89%\n"
     ]
    }
   ],
   "source": [
    "test_acc,train_acc=model_train(act_model_1, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tanh Activation function with dropout  \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ActivatedNeuralNetwork(nn.Module):\n",
    "    def __init__(self,prob):\n",
    "        super(ActivatedNeuralNetwork,self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 16)\n",
    "        self.Softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(prob[0])\n",
    "        self.linear2 = nn.Linear(16, 8)\n",
    "        self.Softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(prob[1])\n",
    "        self.linear3 = nn.Linear(8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.Softmax(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.Softmax(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear3(x)\n",
    "        x=self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_model_2=ActivatedNeuralNetwork([0.3,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_22312\\44230661.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.Softmax(x)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_22312\\44230661.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.Softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 76.84%\n"
     ]
    }
   ],
   "source": [
    "test_acc,train_acc=model_train(act_model_2, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Leakyrelu Activation function with dropout  \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ActivatedNeuralNetwork(nn.Module):\n",
    "    def __init__(self,prob):\n",
    "        super(ActivatedNeuralNetwork,self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 16)\n",
    "        self.LeakyRelu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(prob[0])\n",
    "        self.linear2 = nn.Linear(16, 8)\n",
    "        self.LeakyRelu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(prob[1])\n",
    "        self.linear3 = nn.Linear(8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.LeakyRelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.LeakyRelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear3(x)\n",
    "        x=self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_model_3=ActivatedNeuralNetwork([0.3,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 77.89%\n"
     ]
    }
   ],
   "source": [
    "test_acc,train_acc=model_train(act_model_3, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning Initilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "## By tunning the activation function the relu activation function with dropout gives the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class InitilizerActivatedDropNeuralNetwork(nn.Module):\n",
    "    def __init__(self,initilz,prob):\n",
    "        super(InitilizerActivatedDropNeuralNetwork,self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(prob[0])\n",
    "        self.linear2 = nn.Linear(16, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(prob[1])\n",
    "        self.linear3 = nn.Linear(8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        if initilz=='uni':\n",
    "            nn.init.uniform_(self.linear1.weight, a=-0.1, b=0.1)\n",
    "            nn.init.uniform_(self.linear2.weight, a=-0.1, b=0.1)\n",
    "        elif initilz=='xav':\n",
    "            nn.init.xavier_uniform_(self.linear1.weight)\n",
    "            nn.init.xavier_uniform_(self.linear2.weight)\n",
    "        elif initilz=='orth':\n",
    "            nn.init.orthogonal_(self.linear1.weight)\n",
    "            nn.init.orthogonal_(self.linear1.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "            x = self.linear1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.linear2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.linear3(x)\n",
    "            x=self.sigmoid(x)\n",
    "            return x\n",
    "#     super(InitActivDropoutNeuralNetwork,self).__init__()\n",
    "#     self.h1 = nn.Linear(2,16)\n",
    "#     self.dropout1 = nn.Dropout(p=dropout_probs[0])\n",
    "#     self.h2 = nn.Linear(18,9)\n",
    "#     self.dropout2 = nn.Dropout(p=dropout_probs[1])\n",
    "#     self.h3 = nn.Linear(9, 1)\n",
    "#     self.sigmoid = nn.Sigmoid()\n",
    "#     if activ_func == 'relu':\n",
    "#       self.activation = nn.ReLU()\n",
    "#     elif activ_func == 'tanh':\n",
    "#       self.activation = nn.Tanh()\n",
    "#     elif activ_func == 'leaky_relu':\n",
    "#       self.activation = nn.LeakyReLU()\n",
    "#     if inz=='uni':\n",
    "#       init.uniform_(self.h1.weight, a=-0.05, b=0.05)\n",
    "#       init.uniform_(self.h2.weight, a=-0.05, b=0.05)\n",
    "#     elif inz=='xav':\n",
    "#       init.xavier_uniform_(self.h1.weight)\n",
    "#       init.xavier_uniform_(self.h2.weight)\n",
    "#     elif inz=='orth':\n",
    "#       init.kaiming_uniform_(self.h1.weight, nonlinearity='leaky_relu')\n",
    "#       init.kaiming_uniform_(self.h2.weight, nonlinearity='leaky_relu')\n",
    "\n",
    "\n",
    "#   def forward(self,x):\n",
    "#     x = self.activation(self.h1(x))\n",
    "#     x=self.dropout1(x)\n",
    "#     x = self.activation(self.h2(x))\n",
    "#     x=self.dropout2(x)\n",
    "#     x = self.sigmoid(self.h3(x))\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer_model1 = InitilizerActivatedDropNeuralNetwork('uni',[0.3,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 77.37%\n"
     ]
    }
   ],
   "source": [
    "test_acc,train_acc=model_train(initializer_model1, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer_model2 = InitilizerActivatedDropNeuralNetwork('xav',[0.3,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 76.84%\n"
     ]
    }
   ],
   "source": [
    "test_acc,train_acc=model_train(initializer_model2, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer_model3 = InitilizerActivatedDropNeuralNetwork('orth',[0.3,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 76.84%\n"
     ]
    }
   ],
   "source": [
    "test_acc,train_acc=model_train(initializer_model3, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class BatchnormdropoutNeuralNetwork(nn.Module):\n",
    "    def __init__(self,prob):\n",
    "        super(BatchnormdropoutNeuralNetwork,self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.dropout = nn.Dropout(prob[0])\n",
    "        self.linear2 = nn.Linear(16, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm1d(8)\n",
    "        self.dropout = nn.Dropout(prob[1])\n",
    "        self.linear3 = nn.Linear(8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear3(x)\n",
    "        x=self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_model=BatchnormdropoutNeuralNetwork([0.3,0.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 76.32%\n"
     ]
    }
   ],
   "source": [
    "test_acc,train_acc=model_train(batch_model, X_train, y_train, X_test, y_test)\n",
    "print('Accuracy for test data: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class dropoutNeuralNetwork(nn.Module):\n",
    "    def __init__(self,prob):\n",
    "        super(dropoutNeuralNetwork,self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(prob[0])\n",
    "        self.linear2 = nn.Linear(16, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(prob[1])\n",
    "        self.linear3 = nn.Linear(8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear3(x)\n",
    "        x=self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, criterion, X, y):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         output = model(X)\n",
    "#         loss = criterion(output, y)\n",
    "#     return loss.item()\n",
    "\n",
    "# val_loss = evaluate(model, criterion, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_function= nn.BCELoss() \n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# n_epochs = 100\n",
    "# batch_size = 50\n",
    "# least_loss=1\n",
    "# for epoch in range(n_epochs):\n",
    "#     for start in range(0, len(X_train), batch_size):\n",
    "#                 # take a batch\n",
    "#                 X_batch = X_train[start:start+batch_size]\n",
    "#                 y_batch = y_train[start:start+batch_size]\n",
    "#                 X_batch = torch.FloatTensor(X_batch)\n",
    "#                 y_batch = torch.FloatTensor(y_batch).reshape(-1, 1)\n",
    "#                 # forward pass\n",
    "#                 y_pred = model(X_batch)\n",
    "#                 loss = loss_function(y_pred, y_batch)\n",
    "#                 # backward pass\n",
    "#                 optimizer.zero_grad()\n",
    "#                 loss.backward()\n",
    "#                 # update weights\n",
    "#                 optimizer.step()\n",
    "#     # Evaluate on test set\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(X_test)\n",
    "#         test_loss = criterion(outputs, y_test)\n",
    "#         test_acc = ((outputs.round() == y_test).float().mean()).item()\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}/{20}: Test Loss: {test_loss.item():.4f}, Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: Test Loss: 0.5336, Test Accuracy: 0.7579\n",
      "Epoch 2/20: Test Loss: 0.5336, Test Accuracy: 0.7632\n",
      "Epoch 3/20: Test Loss: 0.5393, Test Accuracy: 0.7474\n",
      "Epoch 4/20: Test Loss: 0.5181, Test Accuracy: 0.7474\n",
      "Epoch 5/20: Test Loss: 0.5301, Test Accuracy: 0.7684\n",
      "Epoch 6/20: Test Loss: 0.5213, Test Accuracy: 0.7737\n",
      "Epoch 7/20: Test Loss: 0.5448, Test Accuracy: 0.7316\n",
      "Epoch 8/20: Test Loss: 0.5114, Test Accuracy: 0.7632\n",
      "Epoch 9/20: Test Loss: 0.5131, Test Accuracy: 0.7526\n",
      "Epoch 10/20: Test Loss: 0.5287, Test Accuracy: 0.7579\n",
      "Epoch 11/20: Test Loss: 0.5242, Test Accuracy: 0.7632\n",
      "Epoch 12/20: Test Loss: 0.5382, Test Accuracy: 0.7632\n",
      "Epoch 13/20: Test Loss: 0.5262, Test Accuracy: 0.7737\n",
      "Epoch 14/20: Test Loss: 0.5440, Test Accuracy: 0.7526\n",
      "Epoch 15/20: Test Loss: 0.5386, Test Accuracy: 0.7474\n",
      "Epoch 16/20: Test Loss: 0.5226, Test Accuracy: 0.7632\n",
      "Epoch 17/20: Test Loss: 0.5285, Test Accuracy: 0.7684\n",
      "Epoch 18/20: Test Loss: 0.5318, Test Accuracy: 0.7579\n",
      "Epoch 19/20: Test Loss: 0.5291, Test Accuracy: 0.7421\n",
      "Epoch 20/20: Test Loss: 0.5267, Test Accuracy: 0.7737\n",
      "Epoch 21/20: Test Loss: 0.5042, Test Accuracy: 0.7632\n",
      "Epoch 22/20: Test Loss: 0.5260, Test Accuracy: 0.7737\n",
      "Epoch 23/20: Test Loss: 0.5240, Test Accuracy: 0.7526\n",
      "Epoch 24/20: Test Loss: 0.5389, Test Accuracy: 0.7579\n",
      "Epoch 25/20: Test Loss: 0.5060, Test Accuracy: 0.7737\n",
      "Epoch 26/20: Test Loss: 0.5307, Test Accuracy: 0.7632\n",
      "Epoch 27/20: Test Loss: 0.5302, Test Accuracy: 0.7526\n",
      "Epoch 28/20: Test Loss: 0.5280, Test Accuracy: 0.7579\n",
      "Epoch 29/20: Test Loss: 0.5178, Test Accuracy: 0.7737\n",
      "Epoch 30/20: Test Loss: 0.5223, Test Accuracy: 0.7737\n",
      "Epoch 31/20: Test Loss: 0.5114, Test Accuracy: 0.7684\n",
      "Epoch 32/20: Test Loss: 0.5365, Test Accuracy: 0.7579\n",
      "Epoch 33/20: Test Loss: 0.5324, Test Accuracy: 0.7526\n",
      "Epoch 34/20: Test Loss: 0.5184, Test Accuracy: 0.7842\n",
      "Epoch 35/20: Test Loss: 0.5149, Test Accuracy: 0.7632\n",
      "Epoch 36/20: Test Loss: 0.5206, Test Accuracy: 0.7684\n",
      "Epoch 37/20: Test Loss: 0.5059, Test Accuracy: 0.7684\n",
      "Epoch 38/20: Test Loss: 0.5224, Test Accuracy: 0.7526\n",
      "Epoch 39/20: Test Loss: 0.5062, Test Accuracy: 0.7474\n",
      "Epoch 40/20: Test Loss: 0.5280, Test Accuracy: 0.7526\n",
      "Epoch 41/20: Test Loss: 0.5246, Test Accuracy: 0.7684\n",
      "Epoch 42/20: Test Loss: 0.5402, Test Accuracy: 0.7526\n",
      "Epoch 43/20: Test Loss: 0.5221, Test Accuracy: 0.7684\n",
      "Epoch 44/20: Test Loss: 0.5322, Test Accuracy: 0.7421\n",
      "Epoch 45/20: Test Loss: 0.5344, Test Accuracy: 0.7526\n",
      "Epoch 46/20: Test Loss: 0.5263, Test Accuracy: 0.7421\n",
      "Epoch 47/20: Test Loss: 0.5020, Test Accuracy: 0.7895\n",
      "Epoch 48/20: Test Loss: 0.5551, Test Accuracy: 0.7421\n",
      "Epoch 49/20: Test Loss: 0.5399, Test Accuracy: 0.7158\n",
      "Epoch 50/20: Test Loss: 0.5313, Test Accuracy: 0.7632\n",
      "Epoch 51/20: Test Loss: 0.5287, Test Accuracy: 0.7737\n",
      "Epoch 52/20: Test Loss: 0.5221, Test Accuracy: 0.7474\n",
      "Epoch 53/20: Test Loss: 0.5264, Test Accuracy: 0.7632\n",
      "Epoch 54/20: Test Loss: 0.5299, Test Accuracy: 0.7632\n",
      "Epoch 55/20: Test Loss: 0.5289, Test Accuracy: 0.7474\n",
      "Epoch 56/20: Test Loss: 0.5374, Test Accuracy: 0.7474\n",
      "Epoch 57/20: Test Loss: 0.5403, Test Accuracy: 0.7526\n",
      "Epoch 58/20: Test Loss: 0.5362, Test Accuracy: 0.7474\n",
      "Epoch 59/20: Test Loss: 0.4998, Test Accuracy: 0.7737\n",
      "Epoch 60/20: Test Loss: 0.4938, Test Accuracy: 0.7842\n",
      "Epoch 61/20: Test Loss: 0.5202, Test Accuracy: 0.7632\n",
      "Epoch 62/20: Test Loss: 0.5256, Test Accuracy: 0.7579\n",
      "Epoch 63/20: Test Loss: 0.5401, Test Accuracy: 0.7211\n",
      "Epoch 64/20: Test Loss: 0.5449, Test Accuracy: 0.7474\n",
      "Epoch 65/20: Test Loss: 0.5166, Test Accuracy: 0.7632\n",
      "Epoch 66/20: Test Loss: 0.5174, Test Accuracy: 0.7632\n",
      "Epoch 67/20: Test Loss: 0.5289, Test Accuracy: 0.7474\n",
      "Epoch 68/20: Test Loss: 0.5149, Test Accuracy: 0.7632\n",
      "Epoch 69/20: Test Loss: 0.5098, Test Accuracy: 0.7684\n",
      "Epoch 70/20: Test Loss: 0.5341, Test Accuracy: 0.7368\n",
      "Epoch 71/20: Test Loss: 0.5257, Test Accuracy: 0.7632\n",
      "Epoch 72/20: Test Loss: 0.5396, Test Accuracy: 0.7211\n",
      "Epoch 73/20: Test Loss: 0.5314, Test Accuracy: 0.7316\n",
      "Epoch 74/20: Test Loss: 0.5256, Test Accuracy: 0.7474\n",
      "Epoch 75/20: Test Loss: 0.5193, Test Accuracy: 0.7632\n",
      "Epoch 76/20: Test Loss: 0.5144, Test Accuracy: 0.7632\n",
      "Epoch 77/20: Test Loss: 0.5114, Test Accuracy: 0.7684\n",
      "Epoch 78/20: Test Loss: 0.5041, Test Accuracy: 0.7684\n",
      "Epoch 79/20: Test Loss: 0.5401, Test Accuracy: 0.7474\n",
      "Epoch 80/20: Test Loss: 0.5346, Test Accuracy: 0.7421\n",
      "Epoch 81/20: Test Loss: 0.5506, Test Accuracy: 0.7316\n",
      "Epoch 82/20: Test Loss: 0.5302, Test Accuracy: 0.7526\n",
      "Epoch 83/20: Test Loss: 0.5188, Test Accuracy: 0.7632\n",
      "Epoch 84/20: Test Loss: 0.5189, Test Accuracy: 0.7579\n",
      "Epoch 85/20: Test Loss: 0.5240, Test Accuracy: 0.7526\n",
      "Epoch 86/20: Test Loss: 0.5197, Test Accuracy: 0.7474\n",
      "Epoch 87/20: Test Loss: 0.5314, Test Accuracy: 0.7474\n",
      "Epoch 88/20: Test Loss: 0.5188, Test Accuracy: 0.7579\n",
      "Epoch 89/20: Test Loss: 0.5189, Test Accuracy: 0.7632\n",
      "Epoch 90/20: Test Loss: 0.5402, Test Accuracy: 0.7579\n",
      "Epoch 91/20: Test Loss: 0.5279, Test Accuracy: 0.7526\n",
      "Epoch 92/20: Test Loss: 0.5353, Test Accuracy: 0.7474\n",
      "Epoch 93/20: Test Loss: 0.5300, Test Accuracy: 0.7579\n",
      "Epoch 94/20: Test Loss: 0.5290, Test Accuracy: 0.7684\n",
      "Epoch 95/20: Test Loss: 0.5194, Test Accuracy: 0.7579\n",
      "Epoch 96/20: Test Loss: 0.4961, Test Accuracy: 0.7737\n",
      "Epoch 97/20: Test Loss: 0.5363, Test Accuracy: 0.7263\n",
      "Epoch 98/20: Test Loss: 0.5351, Test Accuracy: 0.7474\n",
      "Epoch 99/20: Test Loss: 0.5253, Test Accuracy: 0.7579\n",
      "Epoch 100/20: Test Loss: 0.5224, Test Accuracy: 0.7474\n"
     ]
    }
   ],
   "source": [
    "loss_function= nn.BCELoss() \n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "least_loss=1\n",
    "for epoch in range(n_epochs):\n",
    "    for start in range(0, len(X_train), batch_size):\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                X_batch = torch.FloatTensor(X_batch)\n",
    "                y_batch = torch.FloatTensor(y_batch).reshape(-1, 1)\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_function(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "    # Evaluate on test set\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        test_loss = criterion(outputs, y_test)\n",
    "        test_acc = ((outputs.round() == y_test).float().mean()).item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{20}: Test Loss: {test_loss.item():.4f}, Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
